

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Choice Functions &mdash; csrank 1.0.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Discrete Choice Models" href="discretechoice.html" />
    <link rel="prev" title="Object Ranking" href="objectranking.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> csrank
          

          
          </a>

          
            
            
              <div class="version">
                1.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../intro.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples.html">Examples</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../api.html">API Reference</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="objectranking.html">Object Ranking</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Choice Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="discretechoice.html">Discrete Choice Models</a></li>
</ul>
</li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">csrank</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../api.html">API Reference</a> &raquo;</li>
        
      <li>Choice Functions</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/api/choicefunction.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast,
.nboutput.nblast {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast + .nbinput {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="choice-functions">
<h1>Choice Functions<a class="headerlink" href="#choice-functions" title="Permalink to this headline">¶</a></h1>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#csrank.choicefunctions.FATEChoiceFunction" title="csrank.choicefunctions.FATEChoiceFunction"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FATEChoiceFunction</span></code></a>(n_object_features[, …])</p></td>
<td><p>Create a FATE-network architecture for leaning discrete choice function.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#csrank.choicefunctions.FETAChoiceFunction" title="csrank.choicefunctions.FETAChoiceFunction"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FETAChoiceFunction</span></code></a>(n_objects, n_object_features)</p></td>
<td><p>Create a FETA-network architecture for learning choice functions.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#csrank.choicefunctions.CmpNetChoiceFunction" title="csrank.choicefunctions.CmpNetChoiceFunction"><code class="xref py py-obj docutils literal notranslate"><span class="pre">CmpNetChoiceFunction</span></code></a>(n_object_features[, …])</p></td>
<td><p>Create an instance of the <code class="xref py py-class docutils literal notranslate"><span class="pre">CmpNetCore</span></code> architecture for learning a choice function.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#csrank.choicefunctions.RankNetChoiceFunction" title="csrank.choicefunctions.RankNetChoiceFunction"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RankNetChoiceFunction</span></code></a>(n_object_features[, …])</p></td>
<td><p>Create an instance of the <code class="xref py py-class docutils literal notranslate"><span class="pre">RankNetCore</span></code> architecture for learning a object ranking function.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#csrank.choicefunctions.GeneralizedLinearModel" title="csrank.choicefunctions.GeneralizedLinearModel"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GeneralizedLinearModel</span></code></a>(n_object_features[, …])</p></td>
<td><p>Create an instance of the GeneralizedLinearModel model for learning the choice function.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#csrank.choicefunctions.PairwiseSVMChoiceFunction" title="csrank.choicefunctions.PairwiseSVMChoiceFunction"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PairwiseSVMChoiceFunction</span></code></a>(n_object_features)</p></td>
<td><p>Create an instance of the <code class="xref py py-class docutils literal notranslate"><span class="pre">PairwiseSVM</span></code> model for learning a choice function.</p></td>
</tr>
</tbody>
</table>
<span class="target" id="module-csrank.choicefunctions"></span><dl class="class">
<dt id="csrank.choicefunctions.FATEChoiceFunction">
<em class="property">class </em><code class="sig-prename descclassname">csrank.choicefunctions.</code><code class="sig-name descname">FATEChoiceFunction</code><span class="sig-paren">(</span><em class="sig-param">n_object_features</em>, <em class="sig-param">n_hidden_set_layers=2</em>, <em class="sig-param">n_hidden_set_units=2</em>, <em class="sig-param">n_hidden_joint_layers=32</em>, <em class="sig-param">n_hidden_joint_units=32</em>, <em class="sig-param">loss_function=&lt;function binary_crossentropy&gt;</em>, <em class="sig-param">activation='selu'</em>, <em class="sig-param">kernel_initializer='lecun_normal'</em>, <em class="sig-param">kernel_regularizer=&lt;keras.regularizers.L1L2 object&gt;</em>, <em class="sig-param">optimizer=&lt;keras.optimizers.SGD object&gt;</em>, <em class="sig-param">batch_size=256</em>, <em class="sig-param">metrics=None</em>, <em class="sig-param">random_state=None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/csrank/choicefunctions/fate_choice.html#FATEChoiceFunction"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#csrank.choicefunctions.FATEChoiceFunction" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a FATE-network architecture for leaning discrete choice function. The first-aggregate-then-evaluate
approach learns an embedding of each object and then aggregates that into a context representation
<span class="math notranslate nohighlight">\(\mu_{C(x)}\)</span> and then scores each object <span class="math notranslate nohighlight">\(x\)</span> using a generalized utility function
<span class="math notranslate nohighlight">\(U (x, \mu_{C(x)})\)</span>.
To make it computationally efficient we take the the context <span class="math notranslate nohighlight">\(C(x)\)</span> as query set <span class="math notranslate nohighlight">\(Q\)</span>.
The context-representation is evaluated as:</p>
<div class="math notranslate nohighlight">
\[\mu_{C(x)} = \frac{1}{\lvert C(x) \lvert} \sum_{y \in C(x)} \phi(y)\]</div>
<p>where <span class="math notranslate nohighlight">\(\phi \colon \mathcal{X} \to \mathcal{Z}\)</span> maps each object <span class="math notranslate nohighlight">\(y\)</span> to an
<span class="math notranslate nohighlight">\(m\)</span>-dimensional embedding space <span class="math notranslate nohighlight">\(\mathcal{Z} \subseteq \mathbb{R}^m\)</span>.
The choice set is defined as:</p>
<div class="math notranslate nohighlight">
\[c(Q) = \{ x \in Q \lvert \, U (x, \mu_{C(x)}) &gt; t \}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_object_features</strong> (<em>int</em>) – Dimensionality of the feature space of each object</p></li>
<li><p><strong>n_hidden_set_layers</strong> (<em>int</em>) – Number of set layers.</p></li>
<li><p><strong>n_hidden_set_units</strong> (<em>int</em>) – Number of hidden set units.</p></li>
<li><p><strong>n_hidden_joint_layers</strong> (<em>int</em>) – Number of joint layers.</p></li>
<li><p><strong>n_hidden_joint_units</strong> (<em>int</em>) – Number of joint units.</p></li>
<li><p><strong>activation</strong> (<em>string</em><em> or </em><em>function</em>) – Activation function to use in the hidden units</p></li>
<li><p><strong>kernel_initializer</strong> (<em>function</em><em> or </em><em>string</em>) – Initialization function for the weights of each hidden layer</p></li>
<li><p><strong>kernel_regularizer</strong> (<em>function</em><em> or </em><em>string</em>) – Regularizer to use in the hidden units</p></li>
<li><p><strong>optimizer</strong> (<em>string</em><em> or </em><em>function</em>) – Stochastic gradient optimizer</p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – Batch size to use for training</p></li>
<li><p><strong>loss_function</strong> (<em>function</em>) – Differentiable loss function for the score vector</p></li>
<li><p><strong>metrics</strong> (<em>list</em>) – List of evaluation metrics (can be non-differentiable)</p></li>
<li><p><strong>random_state</strong> (<em>int</em><em> or </em><em>object</em>) – Numpy random state</p></li>
<li><p><strong>**kwargs</strong> – Keyword arguments for the &#64;FATENetwork</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="csrank.choicefunctions.FATEChoiceFunction.clear_memory">
<code class="sig-name descname">clear_memory</code><span class="sig-paren">(</span><em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/csrank/choicefunctions/fate_choice.html#FATEChoiceFunction.clear_memory"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#csrank.choicefunctions.FATEChoiceFunction.clear_memory" title="Permalink to this definition">¶</a></dt>
<dd><p>Clear the memory, restores the currently fitted model back to prevent memory leaks.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_objects</strong> (<em>int</em>) – float (n_instances, n_objects, n_features)</p></li>
<li><p><strong>**kwargs</strong> – Keyword arguments for the function</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="csrank.choicefunctions.FATEChoiceFunction.construct_model">
<code class="sig-name descname">construct_model</code><span class="sig-paren">(</span><em class="sig-param">n_features</em>, <em class="sig-param">n_objects</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/csrank/choicefunctions/fate_choice.html#FATEChoiceFunction.construct_model"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#csrank.choicefunctions.FATEChoiceFunction.construct_model" title="Permalink to this definition">¶</a></dt>
<dd><p>Construct the FATE-network architecture using the <code class="xref py py-class docutils literal notranslate"><span class="pre">DeepSet</span></code> to learn the context representation
<span class="math notranslate nohighlight">\(\mu_{C(x)}\)</span> for the given query set/context <span class="math notranslate nohighlight">\(Q=C(x)\)</span>. We construct an input tensor of query
set <span class="math notranslate nohighlight">\(Q\)</span> of size (n_objects, n_features),iterate over it for each object and concatenate the
context-representation feature tensor of size <span class="math notranslate nohighlight">\(\lvert  \mu_{C(x)} \lvert\)</span> into a joint layers.
So, for each object we share the weights in the joint network and the output of this network is used to
learn the generalized latent utility score <span class="math notranslate nohighlight">\(U (x, \mu_{C(x)})\)</span> of each object <span class="math notranslate nohighlight">\(x \in Q\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_features</strong> (<em>int</em>) – Features of the objects for which the network is constructed</p></li>
<li><p><strong>n_objects</strong> (<em>int</em>) – Size of the query sets for which the network is constructed</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>model</strong> (keras <code class="xref py py-class docutils literal notranslate"><span class="pre">Model</span></code>) – Neural network to learn the FATE utility score</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="csrank.choicefunctions.FATEChoiceFunction.fit">
<code class="sig-name descname">fit</code><span class="sig-paren">(</span><em class="sig-param">X</em>, <em class="sig-param">Y</em>, <em class="sig-param">epochs=35</em>, <em class="sig-param">inner_epochs=1</em>, <em class="sig-param">callbacks=None</em>, <em class="sig-param">validation_split=0.1</em>, <em class="sig-param">verbose=0</em>, <em class="sig-param">global_lr=1.0</em>, <em class="sig-param">global_momentum=0.9</em>, <em class="sig-param">min_bucket_size=500</em>, <em class="sig-param">refit=False</em>, <em class="sig-param">tune_size=0.1</em>, <em class="sig-param">thin_thresholds=1</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/csrank/choicefunctions/fate_choice.html#FATEChoiceFunction.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#csrank.choicefunctions.FATEChoiceFunction.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit a generic FATE-network model for learning a choice function on a provided set of queries.</p>
<p>The provided queries can be of a fixed size (numpy arrays) or of varying sizes in which case dictionaries
are expected as input. For varying sizes a meta gradient descent is performed across the
different query sizes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>numpy array</em><em> or </em><em>dict</em>) – Feature vectors of the objects
(n_instances, n_objects, n_features) if numpy array or map from n_objects to numpy arrays</p></li>
<li><p><strong>Y</strong> (<em>numpy array</em><em> or </em><em>dict</em>) – Choices for given objects in the query
(n_instances, n_objects) if numpy array or map from n_objects to numpy arrays</p></li>
<li><p><strong>epochs</strong> (<em>int</em>) – Number of epochs to run if training for a fixed query size or
number of epochs of the meta gradient descent for the variadic model</p></li>
<li><p><strong>inner_epochs</strong> (<em>int</em>) – Number of epochs to train for each query size inside the variadic
model</p></li>
<li><p><strong>callbacks</strong> (<em>list</em>) – List of callbacks to be called during optimization</p></li>
<li><p><strong>validation_split</strong> (<em>float</em><em> (</em><em>range :</em><em> [</em><em>0</em><em>,</em><em>1</em><em>]</em><em>)</em>) – Percentage of instances to split off to validate on</p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) – Print verbose information</p></li>
<li><p><strong>global_lr</strong> (<em>float</em>) – Learning rate of the meta gradient descent (variadic model only)</p></li>
<li><p><strong>global_momentum</strong> (<em>float</em>) – Momentum for the meta gradient descent (variadic model only)</p></li>
<li><p><strong>min_bucket_size</strong> (<em>int</em>) – Restrict the training to queries of a minimum size</p></li>
<li><p><strong>refit</strong> (<em>bool</em>) – If True, create a new model object, otherwise continue fitting the
existing one if one exists.</p></li>
<li><p><strong>tune_size</strong> (<em>float</em><em> (</em><em>range :</em><em> [</em><em>0</em><em>,</em><em>1</em><em>]</em><em>)</em>) – Percentage of instances to split off to tune the threshold for the choice function</p></li>
<li><p><strong>thin_thresholds</strong> (<em>int</em>) – The number of instances of scores to skip while tuning the threshold</p></li>
<li><p><strong>**kwargs</strong> – Keyword arguments for the fit function</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="csrank.choicefunctions.FATEChoiceFunction.predict">
<code class="sig-name descname">predict</code><span class="sig-paren">(</span><em class="sig-param">X</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/csrank/choicefunctions/fate_choice.html#FATEChoiceFunction.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#csrank.choicefunctions.FATEChoiceFunction.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict preferences in the form of rankings or choices for a given collection of sets of objects called
a query set using the function <a class="reference internal" href="#csrank.choicefunctions.FATEChoiceFunction.predict_for_scores" title="csrank.choicefunctions.FATEChoiceFunction.predict_for_scores"><code class="xref py py-meth docutils literal notranslate"><span class="pre">predict_for_scores()</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>dict</em><em> or </em><em>numpy array</em>) – Dictionary with a mapping from the query set size to numpy arrays or a single numpy array of size:
(n_instances, n_objects, n_features)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>Y</strong> (<em>dict or numpy array</em>) – Dictionary with a mapping from the query set size to numpy arrays or a single numpy array containing
predicted preferences of size:
(n_instances, n_objects)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="csrank.choicefunctions.FATEChoiceFunction.predict_for_scores">
<code class="sig-name descname">predict_for_scores</code><span class="sig-paren">(</span><em class="sig-param">scores</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/csrank/choicefunctions/fate_choice.html#FATEChoiceFunction.predict_for_scores"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#csrank.choicefunctions.FATEChoiceFunction.predict_for_scores" title="Permalink to this definition">¶</a></dt>
<dd><p>Binary choice vector <span class="math notranslate nohighlight">\(y\)</span> represents the choices amongst the objects in <span class="math notranslate nohighlight">\(Q\)</span>, such that
<span class="math notranslate nohighlight">\(y(k) = 1\)</span> represents that the object <span class="math notranslate nohighlight">\(x_k\)</span> is chosen and <span class="math notranslate nohighlight">\(y(k) = 0\)</span> represents it is not
chosen. Predict choices for the scores for a given collection of sets of objects (query sets).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>scores</strong> (<em>dict</em><em> or </em><em>numpy array</em>) – Dictionary with a mapping from query set size to numpy arrays
or a single numpy array of size containing scores of each object of size:
(n_instances, n_objects)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>Y</strong> (<em>dict or numpy array</em>) – Dictionary with a mapping from query set size to numpy arrays
or a single numpy array containing predicted choice vectors of size:
(n_instances, n_objects)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="csrank.choicefunctions.FATEChoiceFunction.predict_scores">
<code class="sig-name descname">predict_scores</code><span class="sig-paren">(</span><em class="sig-param">X</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/csrank/choicefunctions/fate_choice.html#FATEChoiceFunction.predict_scores"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#csrank.choicefunctions.FATEChoiceFunction.predict_scores" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict the utility scores for each object in the collection of set of objects called a query set.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>dict</em><em> or </em><em>numpy array</em>) – Dictionary with a mapping from query set size to numpy arrays or a single numpy array of size:
(n_instances, n_objects, n_features)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>Y</strong> (<em>dict or numpy array</em>) – Dictionary with a mapping from query set size to numpy arrays or a single numpy array of size:
(n_instances, n_objects)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="csrank.choicefunctions.FATEChoiceFunction.set_tunable_parameters">
<code class="sig-name descname">set_tunable_parameters</code><span class="sig-paren">(</span><em class="sig-param">n_hidden_set_units=32</em>, <em class="sig-param">n_hidden_set_layers=2</em>, <em class="sig-param">n_hidden_joint_units=32</em>, <em class="sig-param">n_hidden_joint_layers=2</em>, <em class="sig-param">reg_strength=0.0001</em>, <em class="sig-param">learning_rate=0.001</em>, <em class="sig-param">batch_size=128</em>, <em class="sig-param">**point</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/csrank/choicefunctions/fate_choice.html#FATEChoiceFunction.set_tunable_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#csrank.choicefunctions.FATEChoiceFunction.set_tunable_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Set tunable parameters of the FATE-network to the values provided.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_hidden_set_layers</strong> (<em>int</em>) – Number of hidden set layers</p></li>
<li><p><strong>n_hidden_set_units</strong> (<em>int</em>) – Number of hidden set units in each set layer</p></li>
<li><p><strong>n_hidden_joint_units</strong> (<em>int</em>) – Number of hidden joint layers</p></li>
<li><p><strong>n_hidden_joint_layers</strong> (<em>int</em>) – Number of hidden units in each joint layer</p></li>
<li><p><strong>reg_strength</strong> (<em>float</em>) – Regularization strength of the regularizer function applied to the <cite>kernel</cite> weights matrix</p></li>
<li><p><strong>learning_rate</strong> (<em>float</em>) – Learning rate of the stochastic gradient descent algorithm used by the network</p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – Batch size to use during training</p></li>
<li><p><strong>point</strong> (<em>dict</em>) – Dictionary containing parameter values which are not tuned for the network</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="csrank.choicefunctions.FETAChoiceFunction">
<em class="property">class </em><code class="sig-prename descclassname">csrank.choicefunctions.</code><code class="sig-name descname">FETAChoiceFunction</code><span class="sig-paren">(</span><em class="sig-param">n_objects, n_object_features, n_hidden=2, n_units=8, add_zeroth_order_model=False, max_number_of_objects=10, num_subsample=5, loss_function=&lt;function binary_crossentropy&gt;, batch_normalization=False, kernel_regularizer=&lt;keras.regularizers.L1L2 object&gt;, kernel_initializer='lecun_normal', activation='selu', optimizer=&lt;keras.optimizers.SGD object&gt;, metrics=['binary_accuracy'], batch_size=256, random_state=None, **kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/csrank/choicefunctions/feta_choice.html#FETAChoiceFunction"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#csrank.choicefunctions.FETAChoiceFunction" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a FETA-network architecture for learning choice functions.
The first-evaluate-then-aggregate approach approximates the context-dependent utility function using the
first-order utility function <span class="math notranslate nohighlight">\(U_1 \colon \mathcal{X} \times \mathcal{X} \rightarrow [0,1]\)</span>
and zeroth-order utility function  <span class="math notranslate nohighlight">\(U_0 \colon \mathcal{X} \rightarrow [0,1]\)</span>.
The scores each object <span class="math notranslate nohighlight">\(x\)</span> using a context-dependent utility function <span class="math notranslate nohighlight">\(U (x, C_i)\)</span>:</p>
<div class="math notranslate nohighlight">
\[U(x_i, C_i) = U_0(x_i) + \frac{1}{n-1} \sum_{x_j \in Q \setminus \{x_i\}} U_1(x_i , x_j) \, .\]</div>
<p>Training and prediction complexity is quadratic in the number of objects.
The choice set is defined as:</p>
<div class="math notranslate nohighlight">
\[c(Q) = \{ x_i \in Q \lvert \, U (x_i, C_i) &gt; t \}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_objects</strong> (<em>int</em>) – Number of objects in each query set</p></li>
<li><p><strong>n_object_features</strong> (<em>int</em>) – Dimensionality of the feature space of each object</p></li>
<li><p><strong>n_hidden</strong> (<em>int</em>) – Number of hidden layers</p></li>
<li><p><strong>n_units</strong> (<em>int</em>) – Number of hidden units in each layer</p></li>
<li><p><strong>add_zeroth_order_model</strong> (<em>bool</em>) – True if the model should include a latent utility function</p></li>
<li><p><strong>max_number_of_objects</strong> (<em>int</em>) – The maximum number of objects to train from</p></li>
<li><p><strong>num_subsample</strong> (<em>int</em>) – Number of objects to subsample to</p></li>
<li><p><strong>loss_function</strong> (<em>function</em>) – Differentiable loss function for the score vector</p></li>
<li><p><strong>batch_normalization</strong> (<em>bool</em>) – Whether to use batch normalization in the hidden layers</p></li>
<li><p><strong>kernel_regularizer</strong> (<em>function</em>) – Regularizer to use in the hidden units</p></li>
<li><p><strong>kernel_initializer</strong> (<em>function</em><em> or </em><em>string</em>) – Initialization function for the weights of each hidden layer</p></li>
<li><p><strong>activation</strong> (<em>string</em><em> or </em><em>function</em>) – Activation function to use in the hidden units</p></li>
<li><p><strong>optimizer</strong> (<em>string</em><em> or </em><em>function</em>) – Stochastic gradient optimizer</p></li>
<li><p><strong>metrics</strong> (<em>list</em>) – List of evaluation metrics (can be non-differentiable)</p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – Batch size to use for training</p></li>
<li><p><strong>random_state</strong> (<em>int</em><em> or </em><em>object</em>) – Numpy random state</p></li>
<li><p><strong>**kwargs</strong> – Keyword arguments for the hidden units</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="csrank.choicefunctions.FETAChoiceFunction.clear_memory">
<code class="sig-name descname">clear_memory</code><span class="sig-paren">(</span><em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/csrank/choicefunctions/feta_choice.html#FETAChoiceFunction.clear_memory"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#csrank.choicefunctions.FETAChoiceFunction.clear_memory" title="Permalink to this definition">¶</a></dt>
<dd><p>Clear the memory, restores the currently fitted model back to prevent memory leaks.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>**kwargs</strong> – Keyword arguments for the function</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="csrank.choicefunctions.FETAChoiceFunction.construct_model">
<code class="sig-name descname">construct_model</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/csrank/choicefunctions/feta_choice.html#FETAChoiceFunction.construct_model"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#csrank.choicefunctions.FETAChoiceFunction.construct_model" title="Permalink to this definition">¶</a></dt>
<dd><p>Construct the <span class="math notranslate nohighlight">\(1\)</span>-st order and <span class="math notranslate nohighlight">\(0\)</span>-th order models, which are used to approximate the
<span class="math notranslate nohighlight">\(U_1(x, C(x))\)</span> and the <span class="math notranslate nohighlight">\(U_0(x)\)</span> utilities respectively. For each pair of objects in
<span class="math notranslate nohighlight">\(x_i, x_j \in Q\)</span> <span class="math notranslate nohighlight">\(U_1(x, C(x))\)</span> we construct <code class="xref py py-class docutils literal notranslate"><span class="pre">CmpNetCore</span></code> with weight sharing to
approximate a pairwise-matrix. A pairwise matrix with index (i,j) corresponds to the <span class="math notranslate nohighlight">\(U_1(x_i,x_j)\)</span>
is a measure of how favorable it is to choose <span class="math notranslate nohighlight">\(x_i\)</span> over <span class="math notranslate nohighlight">\(x_j\)</span>. Using this matrix we calculate
the borda score for each object to calculate <span class="math notranslate nohighlight">\(U_1(x, C(x))\)</span>. For <cite>0</cite>-th order model we construct
<span class="math notranslate nohighlight">\(\lvert Q \lvert\)</span> sequential networks whose weights are shared to evaluate the <span class="math notranslate nohighlight">\(U_0(x)\)</span> for
each object in the query set <span class="math notranslate nohighlight">\(Q\)</span>. The output mode is using sigmoid activation.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>model</strong> (keras <code class="xref py py-class docutils literal notranslate"><span class="pre">Model</span></code>) – Neural network to learn the FETA utility score</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="csrank.choicefunctions.FETAChoiceFunction.fit">
<code class="sig-name descname">fit</code><span class="sig-paren">(</span><em class="sig-param">X</em>, <em class="sig-param">Y</em>, <em class="sig-param">epochs=10</em>, <em class="sig-param">callbacks=None</em>, <em class="sig-param">validation_split=0.1</em>, <em class="sig-param">tune_size=0.1</em>, <em class="sig-param">thin_thresholds=1</em>, <em class="sig-param">verbose=0</em>, <em class="sig-param">**kwd</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/csrank/choicefunctions/feta_choice.html#FETAChoiceFunction.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#csrank.choicefunctions.FETAChoiceFunction.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit a FETA-Network for learning a choice function on the provided set of queries X and preferences Y of
those objects. The provided queries and corresponding preferences are of a fixed size (numpy arrays).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>numpy array</em><em> (</em><em>n_instances</em><em>, </em><em>n_objects</em><em>, </em><em>n_features</em><em>)</em>) – Feature vectors of the objects</p></li>
<li><p><strong>Y</strong> (<em>numpy array</em><em> (</em><em>n_instances</em><em>, </em><em>n_objects</em><em>)</em>) – Choices for given objects in the query</p></li>
<li><p><strong>epochs</strong> (<em>int</em>) – Number of epochs to run if training for a fixed query size</p></li>
<li><p><strong>callbacks</strong> (<em>list</em>) – List of callbacks to be called during optimization</p></li>
<li><p><strong>validation_split</strong> (<em>float</em><em> (</em><em>range :</em><em> [</em><em>0</em><em>,</em><em>1</em><em>]</em><em>)</em>) – Percentage of instances to split off to validate on</p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) – Print verbose information</p></li>
<li><p><strong>tune_size</strong> (<em>float</em><em> (</em><em>range :</em><em> [</em><em>0</em><em>,</em><em>1</em><em>]</em><em>)</em>) – Percentage of instances to split off to tune the threshold for the choice function</p></li>
<li><p><strong>thin_thresholds</strong> (<em>int</em>) – The number of instances of scores to skip while tuning the threshold</p></li>
<li><p><strong>**kwd</strong> – Keyword arguments for the fit function</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="csrank.choicefunctions.FETAChoiceFunction.predict">
<code class="sig-name descname">predict</code><span class="sig-paren">(</span><em class="sig-param">X</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/csrank/choicefunctions/feta_choice.html#FETAChoiceFunction.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#csrank.choicefunctions.FETAChoiceFunction.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict preferences in the form of rankings or choices for a given collection of sets of objects called
a query set using the function <a class="reference internal" href="#csrank.choicefunctions.FETAChoiceFunction.predict_for_scores" title="csrank.choicefunctions.FETAChoiceFunction.predict_for_scores"><code class="xref py py-meth docutils literal notranslate"><span class="pre">predict_for_scores()</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>dict</em><em> or </em><em>numpy array</em>) – Dictionary with a mapping from the query set size to numpy arrays or a single numpy array of size:
(n_instances, n_objects, n_features)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>Y</strong> (<em>dict or numpy array</em>) – Dictionary with a mapping from the query set size to numpy arrays or a single numpy array containing
predicted preferences of size:
(n_instances, n_objects)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="csrank.choicefunctions.FETAChoiceFunction.predict_for_scores">
<code class="sig-name descname">predict_for_scores</code><span class="sig-paren">(</span><em class="sig-param">scores</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/csrank/choicefunctions/feta_choice.html#FETAChoiceFunction.predict_for_scores"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#csrank.choicefunctions.FETAChoiceFunction.predict_for_scores" title="Permalink to this definition">¶</a></dt>
<dd><p>Binary choice vector <span class="math notranslate nohighlight">\(y\)</span> represents the choices amongst the objects in <span class="math notranslate nohighlight">\(Q\)</span>, such that
<span class="math notranslate nohighlight">\(y(k) = 1\)</span> represents that the object <span class="math notranslate nohighlight">\(x_k\)</span> is chosen and <span class="math notranslate nohighlight">\(y(k) = 0\)</span> represents it is not
chosen. Predict choices for the scores for a given collection of sets of objects (query sets).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>scores</strong> (<em>dict</em><em> or </em><em>numpy array</em>) – Dictionary with a mapping from query set size to numpy arrays
or a single numpy array of size containing scores of each object of size:
(n_instances, n_objects)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>Y</strong> (<em>dict or numpy array</em>) – Dictionary with a mapping from query set size to numpy arrays
or a single numpy array containing predicted choice vectors of size:
(n_instances, n_objects)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="csrank.choicefunctions.FETAChoiceFunction.predict_scores">
<code class="sig-name descname">predict_scores</code><span class="sig-paren">(</span><em class="sig-param">X</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/csrank/choicefunctions/feta_choice.html#FETAChoiceFunction.predict_scores"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#csrank.choicefunctions.FETAChoiceFunction.predict_scores" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict the utility scores for each object in the collection of set of objects called a query set.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>dict</em><em> or </em><em>numpy array</em>) – Dictionary with a mapping from query set size to numpy arrays or a single numpy array of size:
(n_instances, n_objects, n_features)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>Y</strong> (<em>dict or numpy array</em>) – Dictionary with a mapping from query set size to numpy arrays or a single numpy array of size:
(n_instances, n_objects)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="csrank.choicefunctions.FETAChoiceFunction.set_tunable_parameters">
<code class="sig-name descname">set_tunable_parameters</code><span class="sig-paren">(</span><em class="sig-param">n_hidden=32</em>, <em class="sig-param">n_units=2</em>, <em class="sig-param">reg_strength=0.0001</em>, <em class="sig-param">learning_rate=0.001</em>, <em class="sig-param">batch_size=128</em>, <em class="sig-param">**point</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/csrank/choicefunctions/feta_choice.html#FETAChoiceFunction.set_tunable_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#csrank.choicefunctions.FETAChoiceFunction.set_tunable_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Set tunable parameters of the FETA-network to the values provided.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_hidden</strong> (<em>int</em>) – Number of hidden layers used in the scoring network</p></li>
<li><p><strong>n_units</strong> (<em>int</em>) – Number of hidden units in each layer of the scoring network</p></li>
<li><p><strong>reg_strength</strong> (<em>float</em>) – Regularization strength of the regularizer function applied to the <cite>kernel</cite> weights matrix</p></li>
<li><p><strong>learning_rate</strong> (<em>float</em>) – Learning rate of the stochastic gradient descent algorithm used by the network</p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – Batch size to use during training</p></li>
<li><p><strong>point</strong> (<em>dict</em>) – Dictionary containing parameter values which are not tuned for the network</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="csrank.choicefunctions.FETAChoiceFunction.sub_sampling">
<code class="sig-name descname">sub_sampling</code><span class="sig-paren">(</span><em class="sig-param">X</em>, <em class="sig-param">Y</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/csrank/choicefunctions/feta_choice.html#FETAChoiceFunction.sub_sampling"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#csrank.choicefunctions.FETAChoiceFunction.sub_sampling" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="csrank.choicefunctions.CmpNetChoiceFunction">
<em class="property">class </em><code class="sig-prename descclassname">csrank.choicefunctions.</code><code class="sig-name descname">CmpNetChoiceFunction</code><span class="sig-paren">(</span><em class="sig-param">n_object_features, n_hidden=2, n_units=8, loss_function='binary_crossentropy', batch_normalization=True, kernel_regularizer=&lt;keras.regularizers.L1L2 object&gt;, kernel_initializer='lecun_normal', activation='relu', optimizer=&lt;keras.optimizers.SGD object&gt;, metrics=['binary_accuracy'], batch_size=256, random_state=None, **kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/csrank/choicefunctions/cmpnet_choice.html#CmpNetChoiceFunction"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#csrank.choicefunctions.CmpNetChoiceFunction" title="Permalink to this definition">¶</a></dt>
<dd><p>Create an instance of the <code class="xref py py-class docutils literal notranslate"><span class="pre">CmpNetCore</span></code> architecture for learning a choice function.
CmpNet breaks the preferences in form of rankings into pairwise comparisons and learns a pairwise model for
the each pair of object in the underlying set. For prediction list of objects is converted in pair of
objects and the pairwise predicate is evaluated using them. The outputs of the network for each pair of
objects <span class="math notranslate nohighlight">\(U(x_1,x_2), U(x_2,x_1)\)</span> are evaluated.
<span class="math notranslate nohighlight">\(U(x_1,x_2)\)</span> is a measure of how favorable it is to choose <span class="math notranslate nohighlight">\(x_1\)</span> over <span class="math notranslate nohighlight">\(x_2\)</span>.
The utility score of object <span class="math notranslate nohighlight">\(x_i\)</span> in query set <span class="math notranslate nohighlight">\(Q = \{ x_1 , \ldots , x_n \}\)</span> is evaluated as:</p>
<div class="math notranslate nohighlight">
\[U(x_i) = \left\{ \frac{1}{n-1} \sum_{j \in [n] \setminus \{i\}} U_1(x_i , x_j)\right\}\]</div>
<p>The choice set is defined as:</p>
<div class="math notranslate nohighlight">
\[c(Q) = \{ x_i \in Q \lvert \, U(x_i) &gt; t \}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_object_features</strong> (<em>int</em>) – Number of features of the object space</p></li>
<li><p><strong>n_hidden</strong> (<em>int</em>) – Number of hidden layers used in the scoring network</p></li>
<li><p><strong>n_units</strong> (<em>int</em>) – Number of hidden units in each layer of the scoring network</p></li>
<li><p><strong>loss_function</strong> (<em>function</em><em> or </em><em>string</em>) – Loss function to be used for the binary decision task of the pairwise comparisons</p></li>
<li><p><strong>batch_normalization</strong> (<em>bool</em>) – Whether to use batch normalization in each hidden layer</p></li>
<li><p><strong>kernel_regularizer</strong> (<em>function</em>) – Regularizer function applied to all the hidden weight matrices.</p></li>
<li><p><strong>activation</strong> (<em>function</em><em> or </em><em>string</em>) – Type of activation function to use in each hidden layer</p></li>
<li><p><strong>optimizer</strong> (<em>function</em><em> or </em><em>string</em>) – Optimizer to use during stochastic gradient descent</p></li>
<li><p><strong>metrics</strong> (<em>list</em>) – List of metrics to evaluate during training (can be non-differentiable)</p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – Batch size to use during training</p></li>
<li><p><strong>random_state</strong> (<em>int</em><em>, </em><em>RandomState instance</em><em> or </em><em>None</em>) – Seed of the pseudorandom generator or a RandomState instance</p></li>
<li><p><strong>**kwargs</strong> – Keyword arguments for the algorithms</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p>[1] Leonardo Rigutini, Tiziano Papini, Marco Maggini, and Franco Scarselli. 2011. SortNet: Learning to Rank by a Neural Preference Function. IEEE Trans. Neural Networks 22, 9 (2011), 1368–1380. <a class="reference external" href="https://doi.org/10.1109/TNN.2011.2160875">https://doi.org/10.1109/TNN.2011.2160875</a></p>
<dl class="method">
<dt id="csrank.choicefunctions.CmpNetChoiceFunction.clear_memory">
<code class="sig-name descname">clear_memory</code><span class="sig-paren">(</span><em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/csrank/choicefunctions/cmpnet_choice.html#CmpNetChoiceFunction.clear_memory"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#csrank.choicefunctions.CmpNetChoiceFunction.clear_memory" title="Permalink to this definition">¶</a></dt>
<dd><p>Clear the memory, restores the currently fitted model back to prevent memory leaks.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>**kwargs</strong> – Keyword arguments for the function</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="csrank.choicefunctions.CmpNetChoiceFunction.construct_model">
<code class="sig-name descname">construct_model</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/csrank/choicefunctions/cmpnet_choice.html#CmpNetChoiceFunction.construct_model"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#csrank.choicefunctions.CmpNetChoiceFunction.construct_model" title="Permalink to this definition">¶</a></dt>
<dd><p>Construct the CmpNet which is used to approximate the <span class="math notranslate nohighlight">\(U_1(x_i,x_j)\)</span>. For each pair of objects in
<span class="math notranslate nohighlight">\(x_i, x_j \in Q\)</span> we construct two sub-networks with weight sharing in all hidden layers.
The output of these networks are connected to two sigmoid units that produces the outputs of the network,
i.e., <span class="math notranslate nohighlight">\(U(x_1,x_2), U(x_2,x_1)\)</span> for each pair of objects are evaluated. <span class="math notranslate nohighlight">\(U(x_1,x_2)\)</span> is a measure
of how favorable it is to choose <span class="math notranslate nohighlight">\(x_1\)</span> over <span class="math notranslate nohighlight">\(x_2\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>model</strong> (keras <code class="xref py py-class docutils literal notranslate"><span class="pre">Model</span></code>) – Neural network to learn the CmpNet utility score</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="csrank.choicefunctions.CmpNetChoiceFunction.fit">
<code class="sig-name descname">fit</code><span class="sig-paren">(</span><em class="sig-param">X</em>, <em class="sig-param">Y</em>, <em class="sig-param">epochs=10</em>, <em class="sig-param">callbacks=None</em>, <em class="sig-param">validation_split=0.1</em>, <em class="sig-param">tune_size=0.1</em>, <em class="sig-param">thin_thresholds=1</em>, <em class="sig-param">verbose=0</em>, <em class="sig-param">**kwd</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/csrank/choicefunctions/cmpnet_choice.html#CmpNetChoiceFunction.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#csrank.choicefunctions.CmpNetChoiceFunction.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit a CmptNet model for learning a choice fucntion on the provided set of queries X and preferences Y of
those objects. The provided queries and corresponding preferences are of a fixed size (numpy arrays). For
learning this network the binary cross entropy loss function for a pair of objects <span class="math notranslate nohighlight">\(x_i, x_j \in Q\)</span>
is defined as:</p>
<div class="math notranslate nohighlight">
\[C_{ij} =  -\tilde{P_{ij}}(0)\cdot \log(U(x_i,x_j)) - \tilde{P_{ij}}(1) \cdot \log(U(x_j,x_i)) \ ,\]</div>
<p>where <span class="math notranslate nohighlight">\(\tilde{P_{ij}}\)</span> is ground truth probability of the preference of <span class="math notranslate nohighlight">\(x_i\)</span> over <span class="math notranslate nohighlight">\(x_j\)</span>.
<span class="math notranslate nohighlight">\(\tilde{P_{ij}} = (1,0)\)</span> if <span class="math notranslate nohighlight">\(x_i \succ x_j\)</span> else <span class="math notranslate nohighlight">\(\tilde{P_{ij}} = (0,1)\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>numpy array</em>) – (n_instances, n_objects, n_features)
Feature vectors of the objects</p></li>
<li><p><strong>Y</strong> (<em>numpy array</em>) – (n_instances, n_objects)
Preferences in form of Orderings or Choices for given n_objects</p></li>
<li><p><strong>epochs</strong> (<em>int</em>) – Number of epochs to run if training for a fixed query size</p></li>
<li><p><strong>callbacks</strong> (<em>list</em>) – List of callbacks to be called during optimization</p></li>
<li><p><strong>validation_split</strong> (<em>float</em><em> (</em><em>range :</em><em> [</em><em>0</em><em>,</em><em>1</em><em>]</em><em>)</em>) – Percentage of instances to split off to validate on</p></li>
<li><p><strong>tune_size</strong> (<em>float</em><em> (</em><em>range :</em><em> [</em><em>0</em><em>,</em><em>1</em><em>]</em><em>)</em>) – Percentage of instances to split off to tune the threshold for the choice function</p></li>
<li><p><strong>thin_thresholds</strong> (<em>int</em>) – The number of instances of scores to skip while tuning the threshold</p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) – Print verbose information</p></li>
<li><p><strong>**kwd</strong> – Keyword arguments for the fit function</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="csrank.choicefunctions.CmpNetChoiceFunction.predict">
<code class="sig-name descname">predict</code><span class="sig-paren">(</span><em class="sig-param">X</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/csrank/choicefunctions/cmpnet_choice.html#CmpNetChoiceFunction.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#csrank.choicefunctions.CmpNetChoiceFunction.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict preferences in the form of rankings or choices for a given collection of sets of objects called
a query set using the function <a class="reference internal" href="#csrank.choicefunctions.CmpNetChoiceFunction.predict_for_scores" title="csrank.choicefunctions.CmpNetChoiceFunction.predict_for_scores"><code class="xref py py-meth docutils literal notranslate"><span class="pre">predict_for_scores()</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>dict</em><em> or </em><em>numpy array</em>) – Dictionary with a mapping from the query set size to numpy arrays or a single numpy array of size:
(n_instances, n_objects, n_features)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>Y</strong> (<em>dict or numpy array</em>) – Dictionary with a mapping from the query set size to numpy arrays or a single numpy array containing
predicted preferences of size:
(n_instances, n_objects)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="csrank.choicefunctions.CmpNetChoiceFunction.predict_for_scores">
<code class="sig-name descname">predict_for_scores</code><span class="sig-paren">(</span><em class="sig-param">scores</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/csrank/choicefunctions/cmpnet_choice.html#CmpNetChoiceFunction.predict_for_scores"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#csrank.choicefunctions.CmpNetChoiceFunction.predict_for_scores" title="Permalink to this definition">¶</a></dt>
<dd><p>Binary choice vector <span class="math notranslate nohighlight">\(y\)</span> represents the choices amongst the objects in <span class="math notranslate nohighlight">\(Q\)</span>, such that
<span class="math notranslate nohighlight">\(y(k) = 1\)</span> represents that the object <span class="math notranslate nohighlight">\(x_k\)</span> is chosen and <span class="math notranslate nohighlight">\(y(k) = 0\)</span> represents it is not
chosen. Predict choices for the scores for a given collection of sets of objects (query sets).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>scores</strong> (<em>dict</em><em> or </em><em>numpy array</em>) – Dictionary with a mapping from query set size to numpy arrays
or a single numpy array of size containing scores of each object of size:
(n_instances, n_objects)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>Y</strong> (<em>dict or numpy array</em>) – Dictionary with a mapping from query set size to numpy arrays
or a single numpy array containing predicted choice vectors of size:
(n_instances, n_objects)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="csrank.choicefunctions.CmpNetChoiceFunction.predict_scores">
<code class="sig-name descname">predict_scores</code><span class="sig-paren">(</span><em class="sig-param">X</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/csrank/choicefunctions/cmpnet_choice.html#CmpNetChoiceFunction.predict_scores"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#csrank.choicefunctions.CmpNetChoiceFunction.predict_scores" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict the utility scores for each object in the collection of set of objects called a query set.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>dict</em><em> or </em><em>numpy array</em>) – Dictionary with a mapping from query set size to numpy arrays or a single numpy array of size:
(n_instances, n_objects, n_features)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>Y</strong> (<em>dict or numpy array</em>) – Dictionary with a mapping from query set size to numpy arrays or a single numpy array of size:
(n_instances, n_objects)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="csrank.choicefunctions.CmpNetChoiceFunction.set_tunable_parameters">
<code class="sig-name descname">set_tunable_parameters</code><span class="sig-paren">(</span><em class="sig-param">n_hidden=32</em>, <em class="sig-param">n_units=2</em>, <em class="sig-param">reg_strength=0.0001</em>, <em class="sig-param">learning_rate=0.001</em>, <em class="sig-param">batch_size=128</em>, <em class="sig-param">**point</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/csrank/choicefunctions/cmpnet_choice.html#CmpNetChoiceFunction.set_tunable_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#csrank.choicefunctions.CmpNetChoiceFunction.set_tunable_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Set tunable parameters of the CmpNet network to the values provided.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_hidden</strong> (<em>int</em>) – Number of hidden layers used in the scoring network</p></li>
<li><p><strong>n_units</strong> (<em>int</em>) – Number of hidden units in each layer of the scoring network</p></li>
<li><p><strong>reg_strength</strong> (<em>float</em>) – Regularization strength of the regularizer function applied to the <cite>kernel</cite> weights matrix</p></li>
<li><p><strong>learning_rate</strong> (<em>float</em>) – Learning rate of the stochastic gradient descent algorithm used by the network</p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – Batch size to use during training</p></li>
<li><p><strong>point</strong> (<em>dict</em>) – Dictionary containing parameter values which are not tuned for the network</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="csrank.choicefunctions.RankNetChoiceFunction">
<em class="property">class </em><code class="sig-prename descclassname">csrank.choicefunctions.</code><code class="sig-name descname">RankNetChoiceFunction</code><span class="sig-paren">(</span><em class="sig-param">n_object_features, n_hidden=2, n_units=8, loss_function='binary_crossentropy', batch_normalization=True, kernel_regularizer=&lt;keras.regularizers.L1L2 object&gt;, kernel_initializer='lecun_normal', activation='relu', optimizer=&lt;keras.optimizers.SGD object&gt;, metrics=['binary_accuracy'], batch_size=256, random_state=None, **kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/csrank/choicefunctions/ranknet_choice.html#RankNetChoiceFunction"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#csrank.choicefunctions.RankNetChoiceFunction" title="Permalink to this definition">¶</a></dt>
<dd><p>Create an instance of the <code class="xref py py-class docutils literal notranslate"><span class="pre">RankNetCore</span></code> architecture for learning a object ranking function.
It breaks the preferences into pairwise comparisons and learns a latent utility model for the objects.
This network learns a latent utility score for each object in the given query set
<span class="math notranslate nohighlight">\(Q = \{x_1, \ldots ,x_n\}\)</span> using the equation <span class="math notranslate nohighlight">\(U(x) = F(x, w)\)</span> where <span class="math notranslate nohighlight">\(w\)</span> is the weight
vector. It is estimated using <em>pairwise preferences</em> generated from the choices.
The choice set is defined as:</p>
<div class="math notranslate nohighlight">
\[c(Q) = \{ x_i \in Q \lvert \, U(x_i) &gt; t \}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_object_features</strong> (<em>int</em>) – Number of features of the object space</p></li>
<li><p><strong>n_hidden</strong> (<em>int</em>) – Number of hidden layers used in the scoring network</p></li>
<li><p><strong>n_units</strong> (<em>int</em>) – Number of hidden units in each layer of the scoring network</p></li>
<li><p><strong>loss_function</strong> (<em>function</em><em> or </em><em>string</em>) – Loss function to be used for the binary decision task of the pairwise comparisons</p></li>
<li><p><strong>batch_normalization</strong> (<em>bool</em>) – Whether to use batch normalization in each hidden layer</p></li>
<li><p><strong>kernel_regularizer</strong> (<em>function</em>) – Regularizer function applied to all the hidden weight matrices.</p></li>
<li><p><strong>kernel_initializer</strong> (<em>function</em><em> or </em><em>string</em>) – Initialization function for the weights of each hidden layer</p></li>
<li><p><strong>activation</strong> (<em>function</em><em> or </em><em>string</em>) – Type of activation function to use in each hidden layer</p></li>
<li><p><strong>optimizer</strong> (<em>function</em><em> or </em><em>string</em>) – Optimizer to use during stochastic gradient descent</p></li>
<li><p><strong>metrics</strong> (<em>list</em>) – List of metrics to evaluate during training (can be non-differentiable)</p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – Batch size to use during training</p></li>
<li><p><strong>random_state</strong> (<em>int</em><em>, </em><em>RandomState instance</em><em> or </em><em>None</em>) – Seed of the pseudo-random generator or a RandomState instance</p></li>
<li><p><strong>**kwargs</strong> – Keyword arguments for the algorithms</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p>[1] Burges, C. et al. (2005, August). “Learning to rank using gradient descent.”, In Proceedings of the 22nd international conference on Machine learning (pp. 89-96). ACM.</p>
<p>[2] Burges, C. J. (2010). “From ranknet to lambdarank to lambdamart: An overview.”, Learning, 11(23-581).</p>
<dl class="method">
<dt id="csrank.choicefunctions.RankNetChoiceFunction.clear_memory">
<code class="sig-name descname">clear_memory</code><span class="sig-paren">(</span><em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/csrank/choicefunctions/ranknet_choice.html#RankNetChoiceFunction.clear_memory"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#csrank.choicefunctions.RankNetChoiceFunction.clear_memory" title="Permalink to this definition">¶</a></dt>
<dd><p>Clear the memory, restores the currently fitted model back to prevent memory leaks.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>**kwargs</strong> – Keyword arguments for the function</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="csrank.choicefunctions.RankNetChoiceFunction.construct_model">
<code class="sig-name descname">construct_model</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/csrank/choicefunctions/ranknet_choice.html#RankNetChoiceFunction.construct_model"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#csrank.choicefunctions.RankNetChoiceFunction.construct_model" title="Permalink to this definition">¶</a></dt>
<dd><p>Construct the RankNet which is used to approximate the <span class="math notranslate nohighlight">\(U(x)\)</span> utility. For each pair of objects in
<span class="math notranslate nohighlight">\(x_i, x_j \in Q\)</span> we construct two sub-networks with weight sharing in all hidden layer apart form the
last layer for which weights are mirrored version of each other. The output of these networks are connected
to a sigmoid unit that produces the output <span class="math notranslate nohighlight">\(P_{ij}\)</span> which is the probability of preferring object
<span class="math notranslate nohighlight">\(x_i\)</span> over <span class="math notranslate nohighlight">\(x_j\)</span>, to approximate the <span class="math notranslate nohighlight">\(U(x)\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><strong>model</strong> (keras <code class="xref py py-class docutils literal notranslate"><span class="pre">Model</span></code>) – Neural network to learn the RankNet utility score</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="csrank.choicefunctions.RankNetChoiceFunction.fit">
<code class="sig-name descname">fit</code><span class="sig-paren">(</span><em class="sig-param">X</em>, <em class="sig-param">Y</em>, <em class="sig-param">epochs=10</em>, <em class="sig-param">callbacks=None</em>, <em class="sig-param">validation_split=0.1</em>, <em class="sig-param">tune_size=0.1</em>, <em class="sig-param">thin_thresholds=1</em>, <em class="sig-param">verbose=0</em>, <em class="sig-param">**kwd</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/csrank/choicefunctions/ranknet_choice.html#RankNetChoiceFunction.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#csrank.choicefunctions.RankNetChoiceFunction.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit RankNet model for learning choice function on a provided set of queries. The provided queries can be of
a fixed size (numpy arrays). For learning this network the binary cross entropy loss function for a pair of
objects <span class="math notranslate nohighlight">\(x_i, x_j \in Q\)</span> is defined as:</p>
<div class="math notranslate nohighlight">
\[C_{ij} =  -\tilde{P_{ij}}\log(P_{ij}) - (1 - \tilde{P_{ij}})\log(1 - P{ij}) \enspace,\]</div>
<p>where <span class="math notranslate nohighlight">\(\tilde{P_{ij}}\)</span> is ground truth probability of the preference of <span class="math notranslate nohighlight">\(x_i\)</span> over <span class="math notranslate nohighlight">\(x_j\)</span>.
<span class="math notranslate nohighlight">\(\tilde{P_{ij}} = 1\)</span> if <span class="math notranslate nohighlight">\(x_i \succ x_j\)</span> else <span class="math notranslate nohighlight">\(\tilde{P_{ij}} = 0\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>numpy array</em><em> (</em><em>n_instances</em><em>, </em><em>n_objects</em><em>, </em><em>n_features</em><em>)</em>) – Feature vectors of the objects</p></li>
<li><p><strong>Y</strong> (<em>numpy array</em><em> (</em><em>n_instances</em><em>, </em><em>n_objects</em><em>)</em>) – Preferences in form of Orderings or Choices for given n_objects</p></li>
<li><p><strong>epochs</strong> (<em>int</em>) – Number of epochs to run if training for a fixed query size</p></li>
<li><p><strong>callbacks</strong> (<em>list</em>) – List of callbacks to be called during optimization</p></li>
<li><p><strong>validation_split</strong> (<em>float</em><em> (</em><em>range :</em><em> [</em><em>0</em><em>,</em><em>1</em><em>]</em><em>)</em>) – Percentage of instances to split off to validate on</p></li>
<li><p><strong>tune_size</strong> (<em>float</em><em> (</em><em>range :</em><em> [</em><em>0</em><em>,</em><em>1</em><em>]</em><em>)</em>) – Percentage of instances to split off to tune the threshold for the choice function</p></li>
<li><p><strong>thin_thresholds</strong> (<em>int</em>) – The number of instances of scores to skip while tuning the threshold</p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) – Print verbose information</p></li>
<li><p><strong>**kwd</strong> – Keyword arguments for the fit function</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="csrank.choicefunctions.RankNetChoiceFunction.predict">
<code class="sig-name descname">predict</code><span class="sig-paren">(</span><em class="sig-param">X</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/csrank/choicefunctions/ranknet_choice.html#RankNetChoiceFunction.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#csrank.choicefunctions.RankNetChoiceFunction.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict preferences in the form of rankings or choices for a given collection of sets of objects called
a query set using the function <a class="reference internal" href="#csrank.choicefunctions.RankNetChoiceFunction.predict_for_scores" title="csrank.choicefunctions.RankNetChoiceFunction.predict_for_scores"><code class="xref py py-meth docutils literal notranslate"><span class="pre">predict_for_scores()</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>dict</em><em> or </em><em>numpy array</em>) – Dictionary with a mapping from the query set size to numpy arrays or a single numpy array of size:
(n_instances, n_objects, n_features)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>Y</strong> (<em>dict or numpy array</em>) – Dictionary with a mapping from the query set size to numpy arrays or a single numpy array containing
predicted preferences of size:
(n_instances, n_objects)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="csrank.choicefunctions.RankNetChoiceFunction.predict_for_scores">
<code class="sig-name descname">predict_for_scores</code><span class="sig-paren">(</span><em class="sig-param">scores</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/csrank/choicefunctions/ranknet_choice.html#RankNetChoiceFunction.predict_for_scores"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#csrank.choicefunctions.RankNetChoiceFunction.predict_for_scores" title="Permalink to this definition">¶</a></dt>
<dd><p>Binary choice vector <span class="math notranslate nohighlight">\(y\)</span> represents the choices amongst the objects in <span class="math notranslate nohighlight">\(Q\)</span>, such that
<span class="math notranslate nohighlight">\(y(k) = 1\)</span> represents that the object <span class="math notranslate nohighlight">\(x_k\)</span> is chosen and <span class="math notranslate nohighlight">\(y(k) = 0\)</span> represents it is not
chosen. Predict choices for the scores for a given collection of sets of objects (query sets).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>scores</strong> (<em>dict</em><em> or </em><em>numpy array</em>) – Dictionary with a mapping from query set size to numpy arrays
or a single numpy array of size containing scores of each object of size:
(n_instances, n_objects)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>Y</strong> (<em>dict or numpy array</em>) – Dictionary with a mapping from query set size to numpy arrays
or a single numpy array containing predicted choice vectors of size:
(n_instances, n_objects)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="csrank.choicefunctions.RankNetChoiceFunction.predict_scores">
<code class="sig-name descname">predict_scores</code><span class="sig-paren">(</span><em class="sig-param">X</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/csrank/choicefunctions/ranknet_choice.html#RankNetChoiceFunction.predict_scores"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#csrank.choicefunctions.RankNetChoiceFunction.predict_scores" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict the utility scores for each object in the collection of set of objects called a query set.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>dict</em><em> or </em><em>numpy array</em>) – Dictionary with a mapping from query set size to numpy arrays or a single numpy array of size:
(n_instances, n_objects, n_features)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>Y</strong> (<em>dict or numpy array</em>) – Dictionary with a mapping from query set size to numpy arrays or a single numpy array of size:
(n_instances, n_objects)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="csrank.choicefunctions.RankNetChoiceFunction.set_tunable_parameters">
<code class="sig-name descname">set_tunable_parameters</code><span class="sig-paren">(</span><em class="sig-param">n_hidden=32</em>, <em class="sig-param">n_units=2</em>, <em class="sig-param">reg_strength=0.0001</em>, <em class="sig-param">learning_rate=0.001</em>, <em class="sig-param">batch_size=128</em>, <em class="sig-param">**point</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/csrank/choicefunctions/ranknet_choice.html#RankNetChoiceFunction.set_tunable_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#csrank.choicefunctions.RankNetChoiceFunction.set_tunable_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Set tunable parameters of the RankNet network to the values provided.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_hidden</strong> (<em>int</em>) – Number of hidden layers used in the scoring network</p></li>
<li><p><strong>n_units</strong> (<em>int</em>) – Number of hidden units in each layer of the scoring network</p></li>
<li><p><strong>reg_strength</strong> (<em>float</em>) – Regularization strength of the regularizer function applied to the <cite>kernel</cite> weights matrix</p></li>
<li><p><strong>learning_rate</strong> (<em>float</em>) – Learning rate of the stochastic gradient descent algorithm used by the network</p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – Batch size to use during training</p></li>
<li><p><strong>point</strong> (<em>dict</em>) – Dictionary containing parameter values which are not tuned for the network</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="csrank.choicefunctions.GeneralizedLinearModel">
<em class="property">class </em><code class="sig-prename descclassname">csrank.choicefunctions.</code><code class="sig-name descname">GeneralizedLinearModel</code><span class="sig-paren">(</span><em class="sig-param">n_object_features</em>, <em class="sig-param">regularization='l2'</em>, <em class="sig-param">random_state=None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/csrank/choicefunctions/generalized_linear_model.html#GeneralizedLinearModel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#csrank.choicefunctions.GeneralizedLinearModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Create an instance of the GeneralizedLinearModel model for learning the choice function. This model is
adapted from the multinomial logit model <code class="xref py py-class docutils literal notranslate"><span class="pre">csrank.discretechoice.multinomial_logit_model.MultinomialLogitModel</span></code>.
The utility score for each object in query set <span class="math notranslate nohighlight">\(Q\)</span> is defined as <span class="math notranslate nohighlight">\(U(x) = w \cdot x\)</span>,
where <span class="math notranslate nohighlight">\(w\)</span> is the weight vector. The probability of choosing an object <span class="math notranslate nohighlight">\(x_i\)</span> is defined by taking
sigmoid over the utility scores:</p>
<div class="math notranslate nohighlight">
\[P(x_i \lvert Q) = \frac{1}{1+exp(-U(x_i))}\]</div>
<p>The choice set is defined as:</p>
<div class="math notranslate nohighlight">
\[c(Q) = \{ x_i \in Q \lvert \, P(x_i \lvert Q) &gt; t \}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_object_features</strong> (<em>int</em>) – Number of features of the object space</p></li>
<li><p><strong>regularization</strong> (<em>string</em><em>, </em><em>optional</em>) – Regularization technique to be used for estimating the weights</p></li>
<li><p><strong>random_state</strong> (<em>int</em><em> or </em><em>object</em>) – Numpy random state</p></li>
<li><p><strong>**kwargs</strong> – Keyword arguments for the algorithms</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p>[1] Kenneth E Train. „Discrete choice methods with simulation“. In: Cambridge university press, 2009. Chap Logit, pp. 41–86.</p>
<p>[2] Kenneth Train. Qualitative choice analysis. Cambridge, MA: MIT Press, 1986</p>
<dl class="method">
<dt id="csrank.choicefunctions.GeneralizedLinearModel.construct_model">
<code class="sig-name descname">construct_model</code><span class="sig-paren">(</span><em class="sig-param">X</em>, <em class="sig-param">Y</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/csrank/choicefunctions/generalized_linear_model.html#GeneralizedLinearModel.construct_model"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#csrank.choicefunctions.GeneralizedLinearModel.construct_model" title="Permalink to this definition">¶</a></dt>
<dd><p>Constructs the linear logit model which evaluated the utility score as <span class="math notranslate nohighlight">\(U(x) = w \cdot x\)</span>, where
<span class="math notranslate nohighlight">\(w\)</span> is the weight vector. The probability of choosing the object <span class="math notranslate nohighlight">\(x_i\)</span> from the query set
<span class="math notranslate nohighlight">\(Q = \{x_1, \ldots ,x_n\}\)</span> is:</p>
<div class="math notranslate nohighlight">
\[P_i =  P(x_i \lvert Q) = \frac{1}{1+exp(-U(x_i))}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>numpy array</em>) – (n_instances, n_objects, n_features)
Feature vectors of the objects</p></li>
<li><p><strong>Y</strong> (<em>numpy array</em>) – (n_instances, n_objects)
Preferences in form of Choices for given objects</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>model</strong> (pymc3 Model <code class="xref py py-class docutils literal notranslate"><span class="pre">pm.Model</span></code>)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="csrank.choicefunctions.GeneralizedLinearModel.fit">
<code class="sig-name descname">fit</code><span class="sig-paren">(</span><em class="sig-param">X, Y, sampler='variational', tune=500, draws=500, tune_size=0.1, thin_thresholds=1, vi_params={'callbacks': [&lt;pymc3.variational.callbacks.CheckParametersConvergence object&gt;], 'method': 'advi', 'n': 20000}, **kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/csrank/choicefunctions/generalized_linear_model.html#GeneralizedLinearModel.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#csrank.choicefunctions.GeneralizedLinearModel.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit a generalized logit model on the provided set of queries X and choices Y of those objects. The
provided queries and corresponding preferences are of a fixed size (numpy arrays). For learning this network
the binary cross entropy loss function for each object <span class="math notranslate nohighlight">\(x_i \in Q\)</span> is defined as:</p>
<div class="math notranslate nohighlight">
\[C_{i} =  -y(i)\log(P_i) - (1 - y(i))\log(1 - P_i) \enspace,\]</div>
<p>where <span class="math notranslate nohighlight">\(y\)</span> is ground-truth choice vector of the objects in the given query set <span class="math notranslate nohighlight">\(Q\)</span>.
The value <span class="math notranslate nohighlight">\(y(i) = 1\)</span> if object <span class="math notranslate nohighlight">\(x_i\)</span> is chosen else <span class="math notranslate nohighlight">\(y(i) = 0\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>numpy array</em><em> (</em><em>n_instances</em><em>, </em><em>n_objects</em><em>, </em><em>n_features</em><em>)</em>) – Feature vectors of the objects</p></li>
<li><p><strong>Y</strong> (<em>numpy array</em><em> (</em><em>n_instances</em><em>, </em><em>n_objects</em><em>)</em>) – Choices for given objects in the query</p></li>
<li><p><strong>sampler</strong> (<em>{‘variational’</em><em>, </em><em>‘metropolis’</em><em>, </em><em>‘nuts’}</em><em>, </em><em>string</em>) – <p>The sampler used to estimate the posterior mean and mass matrix from the trace</p>
<blockquote>
<div><ul>
<li><p><strong>variational</strong> : Run inference methods to estimate posterior mean and diagonal mass matrix</p></li>
<li><p><strong>metropolis</strong> : Use the MAP as starting point and Metropolis-Hastings sampler</p></li>
<li><p><strong>nuts</strong> : Use the No-U-Turn sampler</p></li>
</ul>
</div></blockquote>
</p></li>
<li><p><strong>vi_params</strong> (<em>dict</em>) – The parameters for the <strong>variational</strong> inference method</p></li>
<li><p><strong>draws</strong> (<em>int</em>) – The number of samples to draw. Defaults to 500. The number of tuned samples are discarded by default</p></li>
<li><p><strong>tune</strong> (<em>int</em>) – Number of iterations to tune, defaults to 500. Ignored when using ‘SMC’. Samplers adjust
the step sizes, scalings or similar during tuning. Tuning samples will be drawn in addition
to the number specified in the <cite>draws</cite> argument, and will be discarded unless
<cite>discard_tuned_samples</cite> is set to False.</p></li>
<li><p><strong>tune_size</strong> (<em>float</em><em> (</em><em>range :</em><em> [</em><em>0</em><em>,</em><em>1</em><em>]</em><em>)</em>) – Percentage of instances to split off to tune the threshold for the choice function</p></li>
<li><p><strong>thin_thresholds</strong> (<em>int</em>) – The number of instances of scores to skip while tuning the threshold</p></li>
<li><p><strong>**kwargs</strong> – Keyword arguments for the fit function</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="csrank.choicefunctions.GeneralizedLinearModel.model_configuration">
<em class="property">property </em><code class="sig-name descname">model_configuration</code><a class="headerlink" href="#csrank.choicefunctions.GeneralizedLinearModel.model_configuration" title="Permalink to this definition">¶</a></dt>
<dd><p>Constructs the dictionary containing the priors for the weight vectors for the model according to the
regularization function. The parameters are:</p>
<blockquote>
<div><ul class="simple">
<li><p><strong>weights</strong> : Weights to evaluates the utility of the objects</p></li>
</ul>
</div></blockquote>
<p>For <code class="docutils literal notranslate"><span class="pre">l1</span></code> regularization the priors are:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\text{mu}_w \sim \text{Normal}(\text{mu}=0, \text{sd}=5.0) \\
\text{b}_w \sim \text{HalfCauchy}(\beta=1.0) \\
\text{weights} \sim \text{Laplace}(\text{mu}=\text{mu}_w, \text{b}=\text{b}_w)\end{split}\]</div>
<p>For <code class="docutils literal notranslate"><span class="pre">l2</span></code> regularization the priors are:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\text{mu}_w \sim \text{Normal}(\text{mu}=0, \text{sd}=5.0) \\
\text{sd}_w \sim \text{HalfCauchy}(\beta=1.0) \\
\text{weights} \sim \text{Normal}(\text{mu}=\text{mu}_w, \text{sd}=\text{sd}_w)\end{split}\]</div>
</dd></dl>

<dl class="method">
<dt id="csrank.choicefunctions.GeneralizedLinearModel.predict">
<code class="sig-name descname">predict</code><span class="sig-paren">(</span><em class="sig-param">X</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/csrank/choicefunctions/generalized_linear_model.html#GeneralizedLinearModel.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#csrank.choicefunctions.GeneralizedLinearModel.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict preferences in the form of rankings or choices for a given collection of sets of objects called
a query set using the function <a class="reference internal" href="#csrank.choicefunctions.GeneralizedLinearModel.predict_for_scores" title="csrank.choicefunctions.GeneralizedLinearModel.predict_for_scores"><code class="xref py py-meth docutils literal notranslate"><span class="pre">predict_for_scores()</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>dict</em><em> or </em><em>numpy array</em>) – Dictionary with a mapping from the query set size to numpy arrays or a single numpy array of size:
(n_instances, n_objects, n_features)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>Y</strong> (<em>dict or numpy array</em>) – Dictionary with a mapping from the query set size to numpy arrays or a single numpy array containing
predicted preferences of size:
(n_instances, n_objects)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="csrank.choicefunctions.GeneralizedLinearModel.predict_for_scores">
<code class="sig-name descname">predict_for_scores</code><span class="sig-paren">(</span><em class="sig-param">scores</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/csrank/choicefunctions/generalized_linear_model.html#GeneralizedLinearModel.predict_for_scores"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#csrank.choicefunctions.GeneralizedLinearModel.predict_for_scores" title="Permalink to this definition">¶</a></dt>
<dd><p>Binary choice vector <span class="math notranslate nohighlight">\(y\)</span> represents the choices amongst the objects in <span class="math notranslate nohighlight">\(Q\)</span>, such that
<span class="math notranslate nohighlight">\(y(k) = 1\)</span> represents that the object <span class="math notranslate nohighlight">\(x_k\)</span> is chosen and <span class="math notranslate nohighlight">\(y(k) = 0\)</span> represents it is not
chosen. Predict choices for the scores for a given collection of sets of objects (query sets).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>scores</strong> (<em>dict</em><em> or </em><em>numpy array</em>) – Dictionary with a mapping from query set size to numpy arrays
or a single numpy array of size containing scores of each object of size:
(n_instances, n_objects)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>Y</strong> (<em>dict or numpy array</em>) – Dictionary with a mapping from query set size to numpy arrays
or a single numpy array containing predicted choice vectors of size:
(n_instances, n_objects)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="csrank.choicefunctions.GeneralizedLinearModel.predict_scores">
<code class="sig-name descname">predict_scores</code><span class="sig-paren">(</span><em class="sig-param">X</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/csrank/choicefunctions/generalized_linear_model.html#GeneralizedLinearModel.predict_scores"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#csrank.choicefunctions.GeneralizedLinearModel.predict_scores" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict the utility scores for each object in the collection of set of objects called a query set.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>dict</em><em> or </em><em>numpy array</em>) – Dictionary with a mapping from query set size to numpy arrays or a single numpy array of size:
(n_instances, n_objects, n_features)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>Y</strong> (<em>dict or numpy array</em>) – Dictionary with a mapping from query set size to numpy arrays or a single numpy array of size:
(n_instances, n_objects)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="csrank.choicefunctions.GeneralizedLinearModel.set_tunable_parameters">
<code class="sig-name descname">set_tunable_parameters</code><span class="sig-paren">(</span><em class="sig-param">regularization='l1'</em>, <em class="sig-param">**point</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/csrank/choicefunctions/generalized_linear_model.html#GeneralizedLinearModel.set_tunable_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#csrank.choicefunctions.GeneralizedLinearModel.set_tunable_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Set tunable parameters of the Generalized Linear model to the values provided.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>regularization</strong> (<em>{‘l1’</em><em>, </em><em>‘l2’}</em><em>, </em><em>string</em>) – Regularizer function (L1 or L2) applied to the <cite>kernel</cite> weights matrix</p></li>
<li><p><strong>point</strong> (<em>dict</em>) – Dictionary containing parameter values which are not tuned for the network</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="csrank.choicefunctions.PairwiseSVMChoiceFunction">
<em class="property">class </em><code class="sig-prename descclassname">csrank.choicefunctions.</code><code class="sig-name descname">PairwiseSVMChoiceFunction</code><span class="sig-paren">(</span><em class="sig-param">n_object_features</em>, <em class="sig-param">C=1.0</em>, <em class="sig-param">tol=0.0001</em>, <em class="sig-param">normalize=True</em>, <em class="sig-param">fit_intercept=True</em>, <em class="sig-param">random_state=None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/csrank/choicefunctions/pairwise_choice.html#PairwiseSVMChoiceFunction"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#csrank.choicefunctions.PairwiseSVMChoiceFunction" title="Permalink to this definition">¶</a></dt>
<dd><p>Create an instance of the <code class="xref py py-class docutils literal notranslate"><span class="pre">PairwiseSVM</span></code> model for learning a choice function.
It learns a linear deterministic utility function of the form <span class="math notranslate nohighlight">\(U(x) = w \cdot x\)</span>, where <span class="math notranslate nohighlight">\(w\)</span> is
the weight vector. It is estimated using <em>pairwise preferences</em> generated from the choices.
The choice set is defined as:</p>
<div class="math notranslate nohighlight">
\[c(Q) = \{ x_i \in Q \lvert \, U(x_i) &gt; t \}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_object_features</strong> (<em>int</em>) – Number of features of the object space</p></li>
<li><p><strong>C</strong> (<em>float</em><em>, </em><em>optional</em>) – Penalty parameter of the error term</p></li>
<li><p><strong>tol</strong> (<em>float</em><em>, </em><em>optional</em>) – Optimization tolerance</p></li>
<li><p><strong>normalize</strong> (<em>bool</em><em>, </em><em>optional</em>) – If True, the data will be normalized before fitting.</p></li>
<li><p><strong>fit_intercept</strong> (<em>bool</em><em>, </em><em>optional</em>) – If True, the linear model will also fit an intercept.</p></li>
<li><p><strong>random_state</strong> (<em>int</em><em>, </em><em>RandomState instance</em><em> or </em><em>None</em><em>, </em><em>optional</em>) – Seed of the pseudorandom generator or a RandomState instance</p></li>
<li><p><strong>**kwargs</strong> – Keyword arguments for the algorithms</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p>[1] Theodoros Evgeniou, Massimiliano Pontil, and Olivier Toubia.„A convex optimization approach to modeling consumer heterogeneity in conjoint estimation“. In: Marketing Science 26.6 (2007), pp. 805–818.</p>
<p>[2] Sebastián Maldonado, Ricardo Montoya, and Richard Weber. „Advanced conjoint analysis using feature selection via support vector machines“. In: European Journal of Operational Research 241.2 (2015), pp. 564 –574.</p>
<dl class="method">
<dt id="csrank.choicefunctions.PairwiseSVMChoiceFunction.fit">
<code class="sig-name descname">fit</code><span class="sig-paren">(</span><em class="sig-param">X</em>, <em class="sig-param">Y</em>, <em class="sig-param">tune_size=0.1</em>, <em class="sig-param">thin_thresholds=1</em>, <em class="sig-param">**kwd</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/csrank/choicefunctions/pairwise_choice.html#PairwiseSVMChoiceFunction.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#csrank.choicefunctions.PairwiseSVMChoiceFunction.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit a generic preference learning model on a provided set of queries.
The provided queries can be of a fixed size (numpy arrays).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>numpy array</em><em> (</em><em>n_instances</em><em>, </em><em>n_objects</em><em>, </em><em>n_features</em><em>)</em>) – Feature vectors of the objects</p></li>
<li><p><strong>Y</strong> (<em>numpy array</em><em> (</em><em>n_instances</em><em>, </em><em>n_objects</em><em>)</em>) – Choices for given objects in the query</p></li>
<li><p><strong>tune_size</strong> (<em>float</em><em> (</em><em>range :</em><em> [</em><em>0</em><em>,</em><em>1</em><em>]</em><em>)</em>) – Percentage of instances to split off to tune the threshold for the choice function</p></li>
<li><p><strong>thin_thresholds</strong> (<em>int</em>) – The number of instances of scores to skip while tuning the threshold</p></li>
<li><p><strong>**kwd</strong> – Keyword arguments for the fit function</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="csrank.choicefunctions.PairwiseSVMChoiceFunction.predict">
<code class="sig-name descname">predict</code><span class="sig-paren">(</span><em class="sig-param">X</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/csrank/choicefunctions/pairwise_choice.html#PairwiseSVMChoiceFunction.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#csrank.choicefunctions.PairwiseSVMChoiceFunction.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict preferences in the form of rankings or choices for a given collection of sets of objects called
a query set using the function <a class="reference internal" href="#csrank.choicefunctions.PairwiseSVMChoiceFunction.predict_for_scores" title="csrank.choicefunctions.PairwiseSVMChoiceFunction.predict_for_scores"><code class="xref py py-meth docutils literal notranslate"><span class="pre">predict_for_scores()</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>dict</em><em> or </em><em>numpy array</em>) – Dictionary with a mapping from the query set size to numpy arrays or a single numpy array of size:
(n_instances, n_objects, n_features)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>Y</strong> (<em>dict or numpy array</em>) – Dictionary with a mapping from the query set size to numpy arrays or a single numpy array containing
predicted preferences of size:
(n_instances, n_objects)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="csrank.choicefunctions.PairwiseSVMChoiceFunction.predict_for_scores">
<code class="sig-name descname">predict_for_scores</code><span class="sig-paren">(</span><em class="sig-param">scores</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/csrank/choicefunctions/pairwise_choice.html#PairwiseSVMChoiceFunction.predict_for_scores"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#csrank.choicefunctions.PairwiseSVMChoiceFunction.predict_for_scores" title="Permalink to this definition">¶</a></dt>
<dd><p>Binary choice vector <span class="math notranslate nohighlight">\(y\)</span> represents the choices amongst the objects in <span class="math notranslate nohighlight">\(Q\)</span>, such that
<span class="math notranslate nohighlight">\(y(k) = 1\)</span> represents that the object <span class="math notranslate nohighlight">\(x_k\)</span> is chosen and <span class="math notranslate nohighlight">\(y(k) = 0\)</span> represents it is not
chosen. Predict choices for the scores for a given collection of sets of objects (query sets).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>scores</strong> (<em>dict</em><em> or </em><em>numpy array</em>) – Dictionary with a mapping from query set size to numpy arrays
or a single numpy array of size containing scores of each object of size:
(n_instances, n_objects)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>Y</strong> (<em>dict or numpy array</em>) – Dictionary with a mapping from query set size to numpy arrays
or a single numpy array containing predicted choice vectors of size:
(n_instances, n_objects)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="csrank.choicefunctions.PairwiseSVMChoiceFunction.predict_scores">
<code class="sig-name descname">predict_scores</code><span class="sig-paren">(</span><em class="sig-param">X</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/csrank/choicefunctions/pairwise_choice.html#PairwiseSVMChoiceFunction.predict_scores"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#csrank.choicefunctions.PairwiseSVMChoiceFunction.predict_scores" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict the utility scores for each object in the collection of set of objects called a query set.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>dict</em><em> or </em><em>numpy array</em>) – Dictionary with a mapping from query set size to numpy arrays or a single numpy array of size:
(n_instances, n_objects, n_features)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>Y</strong> (<em>dict or numpy array</em>) – Dictionary with a mapping from query set size to numpy arrays or a single numpy array of size:
(n_instances, n_objects)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="csrank.choicefunctions.PairwiseSVMChoiceFunction.set_tunable_parameters">
<code class="sig-name descname">set_tunable_parameters</code><span class="sig-paren">(</span><em class="sig-param">C=1.0</em>, <em class="sig-param">tol=0.0001</em>, <em class="sig-param">**point</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/csrank/choicefunctions/pairwise_choice.html#PairwiseSVMChoiceFunction.set_tunable_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#csrank.choicefunctions.PairwiseSVMChoiceFunction.set_tunable_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Set tunable parameters of the PairwiseSVM model to the values provided.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>C</strong> (<em>float</em>) – Penalty parameter of the error term of the SVM classifier</p></li>
<li><p><strong>tol</strong> (<em>float</em>) – Optimization tolerance of the SVM classifier</p></li>
<li><p><strong>point</strong> (<em>dict</em>) – Dictionary containing parameter values which are not tuned for the network</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="discretechoice.html" class="btn btn-neutral float-right" title="Discrete Choice Models" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="objectranking.html" class="btn btn-neutral float-left" title="Object Ranking" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, Karlson Pfannschmidt, Pritha Gupta, Eyke Hüllermeier

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>